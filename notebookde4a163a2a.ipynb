{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11663573,"sourceType":"datasetVersion","datasetId":7319853}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree, export_graphviz\nfrom xgboost import XGBRegressor\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport graphviz\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\ndf = pd.read_csv(\"/kaggle/input/crop-yield/crop yield prediction.csv\") \ndisplay(df.head(157))\ndisplay(df.info())\n\nprint(\"\\nMissing values:\")\nprint(df.isnull().sum())\n\nplt.figure(figsize=(10, 6))\nsns.histplot(df.iloc[:, -1], kde=True, bins=30, color=\"blue\")\nplt.title(\"Crop Yield Distribution\")\nplt.show()\n\nsns.pairplot(df.iloc[:, :5])\nplt.show()\n\nfor col in df.select_dtypes(include=['object']).columns:\n    df[col] = LabelEncoder().fit_transform(df[col])\n\nX = df.drop(columns=[df.columns[-1]]) \ny = df[df.columns[-1]]  \n\nfeature_names = X.columns\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\ny_scaler = MinMaxScaler()\ny = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodels = {\n    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n    \"XGBoost\": XGBRegressor(objective='reg:squarederror', random_state=42),\n    \"Lasso\": Lasso(alpha=1e-5, max_iter=50000),\n    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n    \"Decision Tree\": DecisionTreeRegressor(max_depth=4, random_state=42)  \n}\n\nmodel_scores = {}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    model_scores[name] = {\n        \"MAE\": mean_absolute_error(y_test, y_pred),\n        \"MSE\": mean_squared_error(y_test, y_pred),\n        \"R2 Score\": r2_score(y_test, y_pred)\n    }\n\nfor name, scores in model_scores.items():\n    print(f\"{name} Performance:\")\n    for metric, value in scores.items():\n        print(f\"{metric}: {value:.4f}\")\n    print(\"-\" * 30)\n\ndt_model = models[\"Decision Tree\"]\nplt.figure(figsize=(30, 15), dpi=150)\nplot_tree(dt_model, filled=True, feature_names=feature_names, fontsize=10)\nplt.title(\"Decision Tree Visualization (max_depth=4)\")\nplt.show()\n\ndot_data = export_graphviz(dt_model, out_file=None, feature_names=feature_names, filled=True, rounded=True, special_characters=True)\ngraph = graphviz.Source(dot_data)\ngraph.render(\"decision_tree\")  \n\nbest_model_name = max(model_scores, key=lambda x: model_scores[x]['R2 Score'])\nbest_model = models[best_model_name]\njoblib.dump(best_model, \"crop_yield_model.pkl\")\nprint(f\"Best model '{best_model_name}' saved as crop_yield_model.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T16:49:36.676817Z","iopub.execute_input":"2025-05-03T16:49:36.677039Z","iopub.status.idle":"2025-05-03T16:49:47.239591Z","shell.execute_reply.started":"2025-05-03T16:49:36.677020Z","shell.execute_reply":"2025-05-03T16:49:47.238669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\ndf = pd.read_csv('/kaggle/input/crop-yield/crop yield prediction.csv') \nprint(\"First 5 rows of the dataset:\")\ndisplay(df.head())\nprint(\"\\nDataset Info:\")\ndf.info()\nprint(\"\\nMissing Values:\")\nprint(df.isnull().sum())\nlabel_encoders = {}\nfor column in df.select_dtypes(include=['object']).columns:\n    le = LabelEncoder()\n    df[column] = le.fit_transform(df[column])\n    label_encoders[column] = le\n    X = df.drop('Crop', axis=1) \ny = df['Crop']\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42\n)\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\nprint(\"\\nConfusion Matrix:\")\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:01:20.893538Z","iopub.execute_input":"2025-05-03T17:01:20.894507Z","iopub.status.idle":"2025-05-03T17:01:21.295144Z","shell.execute_reply.started":"2025-05-03T17:01:20.894445Z","shell.execute_reply":"2025-05-03T17:01:21.294385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\ndf = pd.read_csv('/kaggle/input/crop-yield/crop yield prediction.csv') \nprint(\"First 5 rows of the dataset:\")\ndisplay(df.head())\nprint(\"\\nDataset Info:\")\ndf.info()\nprint(\"\\nMissing Values:\")\nprint(df.isnull().sum())\n\npublic class CropData {\n    private String crop;\n    private double precipitation;\n    private double humidity;\n    private double specificHumidity;\n    private double temperature;\n    private int yield;\n\n    public CropData(String crop, double precipitation, double humidity, double specificHumidity, double temperature, int yield) {\n        this.crop = crop;\n        this.precipitation = precipitation;\n        this.humidity = humidity;\n        this.specificHumidity = specificHumidity;\n        this.temperature = temperature;\n        this.yield = yield;\n    }\n\n    public String getCrop() {\n        return crop;\n    }\n\n    public double getPrecipitation() {\n        return precipitation;\n    }\n\n    public double getHumidity() {\n        return humidity;\n    }\n\n    public double getSpecificHumidity() {\n        return specificHumidity;\n    }\n\n    public double getTemperature() {\n        return temperature;\n    }\n\n    public int getYield() {\n        return yield;\n    }\n\n    public static void main(String[] args) {\n        CropData crop1 = new CropData(\"Cocoa, beans\", 2248.92, 83.4, 17.72, 26.01, 11560);\n        System.out.println(\"Crop: \" + crop1.getCrop());\n        System.out.println(\"Precipitation: \" + crop1.getPrecipitation());\n        // Print other details similarly\n    }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:07:27.677841Z","iopub.execute_input":"2025-05-03T17:07:27.678176Z","iopub.status.idle":"2025-05-03T17:07:27.688562Z","shell.execute_reply.started":"2025-05-03T17:07:27.678151Z","shell.execute_reply":"2025-05-03T17:07:27.687384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Load dataset\ndf = pd.read_csv('/kaggle/input/crop-yield/crop yield prediction.csv')\n\nprint(\"First 5 rows of the dataset:\")\ndisplay(df.head())\n\nprint(\"\\nDataset Info:\")\ndf.info()\n\nprint(\"\\nMissing Values:\")\nprint(df.isnull().sum())\n\n# Drop rows with missing values if any\ndf = df.dropna()\n\n# Convert categorical variables to numeric if necessary\nif 'Crop' in df.columns:\n    df['Crop'] = df['Crop'].astype('category').cat.codes\n\n# Feature columns and target\nfeatures = df.drop('Yield', axis=1)\ntarget = df['Yield']\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n\n# Model training\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predictions\ny_pred = model.predict(X_test)\n\n# Evaluation\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"\\nMean Squared Error: {mse:.2f}\")\npublic class CropData {\n    private String crop;\n    private double precipitation;\n    private double humidity;\n    private double specificHumidity;\n    private double temperature;\n    private int yieldValue;\n\n    public CropData(String crop, double precipitation, double humidity, double specificHumidity, double temperature, int yieldValue) {\n        this.crop = crop;\n        this.precipitation = precipitation;\n        this.humidity = humidity;\n        this.specificHumidity = specificHumidity;\n        this.temperature = temperature;\n        this.yieldValue = yieldValue;\n    }\n\n    public String getCrop() {\n        return crop;\n    }\n\n    public double getPrecipitation() {\n        return precipitation;\n    }\n\n    public double getHumidity() {\n        return humidity;\n    }\n\n    public double getSpecificHumidity() {\n        return specificHumidity;\n    }\n\n    public double getTemperature() {\n        return temperature;\n    }\n\n    public int getYieldValue() {\n        return yieldValue;\n    }\n\n    public static void main(String[] args) {\n        CropData crop1 = new CropData(\"Cocoa, beans\", 2248.92, 83.4, 17.72, 26.01, 11560);\n        System.out.println(\"Crop: \" + crop1.getCrop());\n        System.out.println(\"Precipitation: \" + crop1.getPrecipitation());\n        System.out.println(\"Humidity: \" + crop1.getHumidity());\n        System.out.println(\"Specific Humidity: \" + crop1.getSpecificHumidity());\n        System.out.println(\"Temperature: \" + crop1.getTemperature());\n        System.out.println(\"Yield: \" + crop1.getYieldValue());\n    }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:10:31.923031Z","iopub.execute_input":"2025-05-03T17:10:31.923400Z","iopub.status.idle":"2025-05-03T17:10:31.934611Z","shell.execute_reply.started":"2025-05-03T17:10:31.923374Z","shell.execute_reply":"2025-05-03T17:10:31.933548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Load dataset\ndf = pd.read_csv(\"your_dataset.csv\")  # Replace with your actual CSV file name\n\nX = df.drop(\"Yield\", axis=1)\ny = df[\"Yield\"]\n\ncategorical = [\"Crop\"]\nnumerical = X.columns.difference(categorical)\n\npreprocessor = ColumnTransformer([\n    (\"cat\", OneHotEncoder(), categorical)\n], remainder=\"passthrough\")\n\nmodel = Pipeline([\n    (\"pre\", preprocessor),\n    (\"rf\", RandomForestRegressor(random_state=42))\n])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\nprint(\"R²:\", r2_score(y_test, y_pred))\n\njoblib.dump(model, \"crop_yield_model.pkl\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Load the dataset\ndf = pd.read_csv(\"/kaggle/input/crop-yield/crop yield prediction.csv\")  # Replace with your actual CSV file name\n\n# Separate features and target\nX = df.drop(\"Yield\", axis=1)\ny = df[\"Yield\"]\n\n# Preprocessing: One-hot encode the 'Crop' column\ncategorical = [\"Crop\"]\nnumerical = X.columns.difference(categorical)\n\npreprocessor = ColumnTransformer([\n    (\"cat\", OneHotEncoder(), categorical)\n], remainder=\"passthrough\")\n\n# Build a machine learning pipeline\nmodel = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"regressor\", RandomForestRegressor(n_estimators=100, random_state=42))\n])\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Evaluate the model\ny_pred = model.predict(X_test)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\n\nprint(\"✅ Model trained.\")\nprint(f\"📉 RMSE: {rmse:.2f}\")\nprint(f\"📈 R² Score: {r2:.3f}\")\n\n# Save the model\njoblib.dump(model, \"crop_yield_model.pkl\")\nprint(\"💾 Model saved to 'crop_yield_model.pkl'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:26:25.531868Z","iopub.execute_input":"2025-05-03T17:26:25.532200Z","iopub.status.idle":"2025-05-03T17:26:25.768715Z","shell.execute_reply.started":"2025-05-03T17:26:25.532175Z","shell.execute_reply":"2025-05-03T17:26:25.767700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nimport warnings\nimport graphviz\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree, export_graphviz\nfrom xgboost import XGBRegressor\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# === Load Dataset ===\ndf = pd.read_csv(\"/kaggle/input/crop-yield/crop yield prediction.csv\")  # Replace with your actual file name\n\n# === Inspect Data ===\nprint(df.head())\nprint(df.info())\nprint(\"\\nMissing values:\\n\", df.isnull().sum())\n\n# === Visualize Target Variable ===\nplt.figure(figsize=(10, 6))\nsns.histplot(df.iloc[:, -1], kde=True, bins=30, color=\"skyblue\")\nplt.title(\"Crop Yield Distribution\")\nplt.show()\n\n# === Pair Plot ===\nsns.pairplot(df.iloc[:, :5])\nplt.show()\n\n# === Encode Categorical Features ===\nfor col in df.select_dtypes(include=['object']).columns:\n    df[col] = LabelEncoder().fit_transform(df[col])\n\n# === Split Features and Target ===\nX = df.drop(columns=[df.columns[-1]])\ny = df[df.columns[-1]]\n\nfeature_names = X.columns\n\n# === Scale Features and Target ===\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\ny_scaler = MinMaxScaler()\ny_scaled = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n\n# === Split Train/Test ===\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n\n# === Models ===\nmodels = {\n    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n    \"XGBoost\": XGBRegressor(objective='reg:squarederror', random_state=42),\n    \"Lasso\": Lasso(alpha=1e-5, max_iter=50000),\n    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n    \"Decision Tree\": DecisionTreeRegressor(max_depth=4, random_state=42)\n}\n\nmodel_scores = {}\n\n# === Train and Evaluate Models ===\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    model_scores[name] = {\n        \"MAE\": mean_absolute_error(y_test, y_pred),\n        \"MSE\": mean_squared_error(y_test, y_pred),\n        \"R2 Score\": r2_score(y_test, y_pred)\n    }\n\n# === Show Results ===\nfor name, scores in model_scores.items():\n    print(f\"\\n{name} Performance:\")\n    for metric, value in scores.items():\n        print(f\"{metric}: {value:.4f}\")\n    print(\"-\" * 30)\n\n# === Visualize Decision Tree ===\ndt_model = models[\"Decision Tree\"]\nplt.figure(figsize=(30, 15), dpi=150)\nplot_tree(dt_model, filled=True, feature_names=feature_names, fontsize=10)\nplt.title(\"Decision Tree Visualization (max_depth=4)\")\nplt.show()\n\n# Export to Graphviz\ndot_data = export_graphviz(\n    dt_model, out_file=None,\n    feature_names=feature_names,\n    filled=True, rounded=True,\n    special_characters=True\n)\ngraph = graphviz.Source(dot_data)\ngraph.render(\"decision_tree\")  # Saves as decision_tree.pdf\n\n# === Save the Best Model ===\nbest_model_name = max(model_scores, key=lambda x: model_scores[x]['R2 Score'])\nbest_model = models[best_model_name]\njoblib.dump(best_model, \"crop_yield_model.pkl\")\nprint(f\"\\n✅ Best model '{best_model_name}' saved as crop_yield_model.pkl\")\nCrop,Precipitation (mm day-1),Specific Humidity at 2 Meters (g/kg),Relative Humidity at 2 Meters (%),Temperature at 2 Meters (C),Yield\nMaize,4.1,11.3,80.2,25.0,3150\nRice,5.6,12.5,82.1,26.2,3400\n...","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nimport warnings\nimport graphviz\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree, export_graphviz\nfrom xgboost import XGBRegressor\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# === Load Dataset ===\ndf = pd.read_csv(\"/kaggle/input/crop-yield/crop yield prediction.csv\")  # Replace with your actual file name\n\n# === Inspect Data ===\nprint(df.head())\nprint(df.info())\nprint(\"\\nMissing values:\\n\", df.isnull().sum())\n\n# === Visualize Target Variable ===\nplt.figure(figsize=(10, 6))\nsns.histplot(df.iloc[:, -1], kde=True, bins=30, color=\"skyblue\")\nplt.title(\"Crop Yield Distribution\")\nplt.show()\n\n# === Pair Plot ===\nsns.pairplot(df.iloc[:, :5])\nplt.show()\n\n# === Encode Categorical Features ===\nfor col in df.select_dtypes(include=['object']).columns:\n    df[col] = LabelEncoder().fit_transform(df[col])\n\n# === Split Features and Target ===\nX = df.drop(columns=[df.columns[-1]])\ny = df[df.columns[-1]]\n\nfeature_names = X.columns\n\n# === Scale Features and Target ===\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\ny_scaler = MinMaxScaler()\ny_scaled = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n\n# === Split Train/Test ===\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n\n# === Models ===\nmodels = {\n    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n    \"XGBoost\": XGBRegressor(objective='reg:squarederror', random_state=42),\n    \"Lasso\": Lasso(alpha=1e-5, max_iter=50000),\n    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n    \"Decision Tree\": DecisionTreeRegressor(max_depth=4, random_state=42)\n}\n\nmodel_scores = {}\n\n# === Train and Evaluate Models ===\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    model_scores[name] = {\n        \"MAE\": mean_absolute_error(y_test, y_pred),\n        \"MSE\": mean_squared_error(y_test, y_pred),\n        \"R2 Score\": r2_score(y_test, y_pred)\n    }\n\n# === Show Results ===\nfor name, scores in model_scores.items():\n    print(f\"\\n{name} Performance:\")\n    for metric, value in scores.items():\n        print(f\"{metric}: {value:.4f}\")\n    print(\"-\" * 30)\n\n# === Visualize Decision Tree ===\ndt_model = models[\"Decision Tree\"]\nplt.figure(figsize=(30, 15), dpi=150)\nplot_tree(dt_model, filled=True, feature_names=feature_names, fontsize=10)\nplt.title(\"Decision Tree Visualization (max_depth=4)\")\nplt.show()\n\n# Export to Graphviz\ndot_data = export_graphviz(\n    dt_model, out_file=None,\n    feature_names=feature_names,\n    filled=True, rounded=True,\n    special_characters=True\n)\ngraph = graphviz.Source(dot_data)\ngraph.render(\"decision_tree\")  # Saves as decision_tree.pdf\n\n# === Save the Best Model ===\nbest_model_name = max(model_scores, key=lambda x: model_scores[x]['R2 Score'])\nbest_model = models[best_model_name]\njoblib.dump(best_model, \"crop_yield_model.pkl\")\nprint(f\"\\n✅ Best model '{best_model_name}' saved as crop_yield_model.pkl\")\nCrop,Precipitation (mm day-1),Specific Humidity at 2 Meters (g/kg),Relative Humidity at 2 Meters (%),Temperature at 2 Meters (C),Yield\nMaize,4.1,11.3,80.2,25.0,3150\nRice,5.6,12.5,82.1,26.2,3400\n...","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}